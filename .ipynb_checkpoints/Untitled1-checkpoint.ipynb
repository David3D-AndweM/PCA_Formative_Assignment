{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce1f1024-44b2-445a-8310-24260752317b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "FORMATIVE ASSIGNMENT: PRINCIPAL COMPONENT ANALYSIS (PCA)\n",
      "============================================================\n",
      "Dataset: African Import/Export Trade Data\n",
      "Student: David Mwape\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Formative Assignment: Advanced Linear Algebra (PCA)\n",
    "# Working with African Import/Export Trade Data\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"FORMATIVE ASSIGNMENT: PRINCIPAL COMPONENT ANALYSIS (PCA)\")\n",
    "print(\"=\" * 60)\n",
    "print(\"Dataset: African Import/Export Trade Data\")\n",
    "print(\"Student: David Mwape\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8f36bb9-3330-454b-a257-2ff8741590ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully!\n",
      "Dataset Shape: (22, 34)\n",
      "\n",
      "Columns (34 total - meets >10 requirement):\n",
      " 1. DATE\n",
      " 2. TYPE\n",
      " 3. CPC DESCRIPTION\n",
      " 4. EXPORTER NAME\n",
      " 5. IMPORTER NAME\n",
      " 6. DECLARANT NAME\n",
      " 7. Origin Country\n",
      " 8. Destination Country\n",
      " 9. HS CODE\n",
      "10. HS CODE DESCRIPTION\n",
      "11. QUANTITY UOM\n",
      "12. QUANTITY\n",
      "13. NO OF PACKAGE TYPE\n",
      "14. GROSS WEIGHT\n",
      "15. GROSS WEIGHT UOM\n",
      "16. NET WEIGHT\n",
      "17. NET WEIGHT UOM\n",
      "18. PACKAGE TYPE\n",
      "19. CUSTOMS VALUE BWP\n",
      "20. DECLARATION OFFICE\n",
      "21. INVOICE AMOUNT BWP\n",
      "22. FREIGHT BWP\n",
      "23. REGIME\n",
      "24. ITEM NO\n",
      "25. PORT OF ENTRY\n",
      "26. PLACE OF DISCHARGE\n",
      "27. CPC CODE\n",
      "28. CPC GROUP CODE\n",
      "29. Chapter\n",
      "30. HEADING\n",
      "31. SUB HEADING\n",
      "32. CPC GROUP DESCRIPTION\n",
      "33. MONTH\n",
      "34. YEAR\n",
      "\n",
      "==================================================\n",
      "DATASET OVERVIEW\n",
      "==================================================\n",
      "Number of rows: 22\n",
      "Number of columns: 34\n",
      "Memory usage: 0.03 MB\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Load and Explore the African Trade Dataset\n",
    "\n",
    "# Load the dataset from Downloads folder\n",
    "data_path = '/Users/dave/Downloads/Import Export Trade Data Africa.csv'\n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "print(f\"Dataset loaded successfully!\")\n",
    "print(f\"Dataset Shape: {data.shape}\")\n",
    "print(f\"\\nColumns ({len(data.columns)} total - meets >10 requirement):\")\n",
    "for i, col in enumerate(data.columns, 1):\n",
    "    print(f\"{i:2d}. {col}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"DATASET OVERVIEW\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Number of rows: {data.shape[0]}\")\n",
    "print(f\"Number of columns: {data.shape[1]}\")\n",
    "print(f\"Memory usage: {data.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4086035a-85bb-421e-90b2-688b36f552d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA TYPES ANALYSIS:\n",
      "==================================================\n",
      "DATE                      object\n",
      "TYPE                      object\n",
      "CPC DESCRIPTION           object\n",
      "EXPORTER NAME             object\n",
      "IMPORTER NAME             object\n",
      "DECLARANT NAME            object\n",
      "Origin Country            object\n",
      "Destination Country       object\n",
      "HS CODE                    int64\n",
      "HS CODE DESCRIPTION       object\n",
      "QUANTITY UOM              object\n",
      "QUANTITY                 float64\n",
      "NO OF PACKAGE TYPE         int64\n",
      "GROSS WEIGHT             float64\n",
      "GROSS WEIGHT UOM          object\n",
      "NET WEIGHT               float64\n",
      "NET WEIGHT UOM            object\n",
      "PACKAGE TYPE              object\n",
      "CUSTOMS VALUE BWP        float64\n",
      "DECLARATION OFFICE        object\n",
      "INVOICE AMOUNT BWP       float64\n",
      "FREIGHT BWP              float64\n",
      "REGIME                     int64\n",
      "ITEM NO                    int64\n",
      "PORT OF ENTRY             object\n",
      "PLACE OF DISCHARGE        object\n",
      "CPC CODE                   int64\n",
      "CPC GROUP CODE             int64\n",
      "Chapter                    int64\n",
      "HEADING                    int64\n",
      "SUB HEADING                int64\n",
      "CPC GROUP DESCRIPTION     object\n",
      "MONTH                     object\n",
      "YEAR                       int64\n",
      "dtype: object\n",
      "\n",
      "MISSING VALUES:\n",
      "==================================================\n",
      "Series([], dtype: int64)\n",
      "No missing values found!\n",
      "\n",
      "COLUMN CLASSIFICATION:\n",
      "==================================================\n",
      "Numeric columns (16): ['HS CODE', 'QUANTITY', 'NO OF PACKAGE TYPE', 'GROSS WEIGHT', 'NET WEIGHT', 'CUSTOMS VALUE BWP', 'INVOICE AMOUNT BWP', 'FREIGHT BWP', 'REGIME', 'ITEM NO', 'CPC CODE', 'CPC GROUP CODE', 'Chapter', 'HEADING', 'SUB HEADING', 'YEAR']\n",
      "\n",
      "Categorical columns (18): ['DATE', 'TYPE', 'CPC DESCRIPTION', 'EXPORTER NAME', 'IMPORTER NAME', 'DECLARANT NAME', 'Origin Country', 'Destination Country', 'HS CODE DESCRIPTION', 'QUANTITY UOM', 'GROSS WEIGHT UOM', 'NET WEIGHT UOM', 'PACKAGE TYPE', 'DECLARATION OFFICE', 'PORT OF ENTRY', 'PLACE OF DISCHARGE', 'CPC GROUP DESCRIPTION', 'MONTH']\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Data Analysis and Handling Non-Numeric Data\n",
    "\n",
    "# Check data types and missing values\n",
    "print(\"DATA TYPES ANALYSIS:\")\n",
    "print(\"=\"*50)\n",
    "print(data.dtypes)\n",
    "\n",
    "print(\"\\nMISSING VALUES:\")\n",
    "print(\"=\"*50)\n",
    "missing_values = data.isnull().sum()\n",
    "print(missing_values[missing_values > 0])\n",
    "if missing_values.sum() == 0:\n",
    "    print(\"No missing values found!\")\n",
    "\n",
    "# Identify numeric and categorical columns\n",
    "numeric_columns = data.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_columns = data.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "print(f\"\\nCOLUMN CLASSIFICATION:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Numeric columns ({len(numeric_columns)}): {numeric_columns}\")\n",
    "print(f\"\\nCategorical columns ({len(categorical_columns)}): {categorical_columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee0a9ec3-3a5a-4fa3-bc96-b07970fe655d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom Label Encoder created successfully!\n",
      "Ready to encode categorical variables...\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Custom Label Encoding (No sklearn allowed for core operations)\n",
    "\n",
    "class CustomLabelEncoder:\n",
    "    \"\"\"Custom Label Encoder implementation without using sklearn\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.label_mapping = {}\n",
    "        self.reverse_mapping = {}\n",
    "    \n",
    "    def fit_transform(self, data):\n",
    "        \"\"\"Fit the encoder and transform the data\"\"\"\n",
    "        unique_values = sorted(data.unique())\n",
    "        self.label_mapping = {val: idx for idx, val in enumerate(unique_values)}\n",
    "        self.reverse_mapping = {idx: val for val, idx in self.label_mapping.items()}\n",
    "        return data.map(self.label_mapping)\n",
    "    \n",
    "    def transform(self, data):\n",
    "        \"\"\"Transform new data using fitted encoder\"\"\"\n",
    "        return data.map(self.label_mapping)\n",
    "    \n",
    "    def inverse_transform(self, encoded_data):\n",
    "        \"\"\"Convert encoded data back to original values\"\"\"\n",
    "        return encoded_data.map(self.reverse_mapping)\n",
    "\n",
    "print(\"Custom Label Encoder created successfully!\")\n",
    "print(\"Ready to encode categorical variables...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86967cc6-7ab9-4766-b6ad-a55f8224e9c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENCODING CATEGORICAL VARIABLES:\n",
      "==================================================\n",
      "Encoding DATE... (1 unique values)\n",
      "Encoding TYPE... (1 unique values)\n",
      "Encoding CPC DESCRIPTION... (1 unique values)\n",
      "Encoding EXPORTER NAME... (1 unique values)\n",
      "Encoding IMPORTER NAME... (1 unique values)\n",
      "Encoding DECLARANT NAME... (1 unique values)\n",
      "Encoding Origin Country... (1 unique values)\n",
      "Encoding Destination Country... (1 unique values)\n",
      "Encoding HS CODE DESCRIPTION... (22 unique values)\n",
      "Encoding QUANTITY UOM... (1 unique values)\n",
      "Encoding GROSS WEIGHT UOM... (1 unique values)\n",
      "Encoding NET WEIGHT UOM... (1 unique values)\n",
      "Encoding PACKAGE TYPE... (1 unique values)\n",
      "Encoding DECLARATION OFFICE... (1 unique values)\n",
      "Encoding PORT OF ENTRY... (1 unique values)\n",
      "Encoding PLACE OF DISCHARGE... (1 unique values)\n",
      "Encoding CPC GROUP DESCRIPTION... (1 unique values)\n",
      "Encoding MONTH... (1 unique values)\n",
      "\n",
      "✅ Encoding completed! All 18 categorical columns encoded.\n",
      "✅ Final dataset shape: (22, 34)\n",
      "✅ Total features for PCA: 34\n",
      "✅ All columns numeric: True\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Apply Encoding to All Categorical Variables\n",
    "\n",
    "print(\"ENCODING CATEGORICAL VARIABLES:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "data_encoded = data.copy()\n",
    "encoders = {}\n",
    "\n",
    "for col in categorical_columns:\n",
    "    print(f\"Encoding {col}... ({data[col].nunique()} unique values)\")\n",
    "    encoder = CustomLabelEncoder()\n",
    "    data_encoded[col] = encoder.fit_transform(data[col])\n",
    "    encoders[col] = encoder\n",
    "\n",
    "print(f\"\\n✅ Encoding completed! All {len(categorical_columns)} categorical columns encoded.\")\n",
    "print(f\"✅ Final dataset shape: {data_encoded.shape}\")\n",
    "print(f\"✅ Total features for PCA: {data_encoded.shape[1]}\")\n",
    "\n",
    "# Verify all columns are now numeric\n",
    "all_numeric = data_encoded.select_dtypes(include=[np.number])\n",
    "print(f\"✅ All columns numeric: {len(all_numeric.columns) == len(data_encoded.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "146034aa-45dd-47b8-8a22-4cfd3549a743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Custom PCA class implemented successfully!\n",
      "Ready to perform PCA on the African trade dataset...\n"
     ]
    }
   ],
   "source": [
    "# TASK 1: Implement PCA from Scratch\n",
    "# Calculate covariance, eigenvalues, eigenvectors, and project data\n",
    "\n",
    "class CustomPCA:\n",
    "    \"\"\"Custom PCA implementation without using sklearn\"\"\"\n",
    "    \n",
    "    def __init__(self, n_components=None):\n",
    "        self.n_components = n_components\n",
    "        self.components_ = None\n",
    "        self.explained_variance_ = None\n",
    "        self.explained_variance_ratio_ = None\n",
    "        self.mean_ = None\n",
    "        \n",
    "    def fit(self, X):\n",
    "        \"\"\"Fit PCA on the data\"\"\"\n",
    "        # Step 1: Center the data (subtract mean)\n",
    "        self.mean_ = np.mean(X, axis=0)\n",
    "        X_centered = X - self.mean_\n",
    "        \n",
    "        # Step 2: Calculate covariance matrix\n",
    "        n_samples = X.shape[0]\n",
    "        cov_matrix = np.dot(X_centered.T, X_centered) / (n_samples - 1)\n",
    "        \n",
    "        # Step 3: Calculate eigenvalues and eigenvectors\n",
    "        eigenvalues, eigenvectors = np.linalg.eigh(cov_matrix)\n",
    "        \n",
    "        # Step 4: Sort eigenvalues and eigenvectors in descending order\n",
    "        idx = np.argsort(eigenvalues)[::-1]\n",
    "        eigenvalues = eigenvalues[idx]\n",
    "        eigenvectors = eigenvectors[:, idx]\n",
    "        \n",
    "        # Step 5: Store results\n",
    "        if self.n_components is None:\n",
    "            self.n_components = len(eigenvalues)\n",
    "        \n",
    "        self.components_ = eigenvectors[:, :self.n_components].T\n",
    "        self.explained_variance_ = eigenvalues[:self.n_components]\n",
    "        self.explained_variance_ratio_ = self.explained_variance_ / np.sum(eigenvalues)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        \"\"\"Transform data to principal component space\"\"\"\n",
    "        X_centered = X - self.mean_\n",
    "        return np.dot(X_centered, self.components_.T)\n",
    "    \n",
    "    def fit_transform(self, X):\n",
    "        \"\"\"Fit PCA and transform data\"\"\"\n",
    "        return self.fit(X).transform(X)\n",
    "\n",
    "print(\"✅ Custom PCA class implemented successfully!\")\n",
    "print(\"Ready to perform PCA on the African trade dataset...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa4b7959-80c0-45fb-a9ab-d1f1decbf574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APPLYING PCA TO AFRICAN TRADE DATASET:\n",
      "============================================================\n",
      "Input data shape: (22, 34)\n",
      "\n",
      "PCA Results:\n",
      "Transformed data shape: (22, 34)\n",
      "Number of components: 34\n",
      "\n",
      "Explained Variance (first 10 components):\n",
      "--------------------------------------------------\n",
      "PC1: 2083765920888.9241 (100.00%)\n",
      "PC2: 4220441.7605 (0.00%)\n",
      "PC3: 71544.9195 (0.00%)\n",
      "PC4: 54.6871 (0.00%)\n",
      "PC5: 32.5131 (0.00%)\n",
      "PC6: 23.0723 (0.00%)\n",
      "PC7: 11.9989 (0.00%)\n",
      "PC8: 0.0469 (0.00%)\n",
      "PC9: 0.0016 (0.00%)\n",
      "PC10: 0.0003 (0.00%)\n",
      "\n",
      "Cumulative Explained Variance (first 10 components):\n",
      "--------------------------------------------------\n",
      "PC1-PC1: 100.00%\n",
      "PC1-PC2: 100.00%\n",
      "PC1-PC3: 100.00%\n",
      "PC1-PC4: 100.00%\n",
      "PC1-PC5: 100.00%\n",
      "PC1-PC6: 100.00%\n",
      "PC1-PC7: 100.00%\n",
      "PC1-PC8: 100.00%\n",
      "PC1-PC9: 100.00%\n",
      "PC1-PC10: 100.00%\n",
      "\n",
      "✅ Task 1 completed: PCA implemented from scratch!\n"
     ]
    }
   ],
   "source": [
    "# Apply PCA to the African Trade Dataset\n",
    "\n",
    "print(\"APPLYING PCA TO AFRICAN TRADE DATASET:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Convert to numpy array for PCA\n",
    "X = data_encoded.values\n",
    "print(f\"Input data shape: {X.shape}\")\n",
    "\n",
    "# Apply PCA with all components first\n",
    "pca = CustomPCA()\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "print(f\"\\nPCA Results:\")\n",
    "print(f\"Transformed data shape: {X_pca.shape}\")\n",
    "print(f\"Number of components: {len(pca.explained_variance_)}\")\n",
    "\n",
    "# Show explained variance for first 10 components\n",
    "print(f\"\\nExplained Variance (first 10 components):\")\n",
    "print(\"-\" * 50)\n",
    "for i in range(min(10, len(pca.explained_variance_))):\n",
    "    print(f\"PC{i+1}: {pca.explained_variance_[i]:.4f} ({pca.explained_variance_ratio_[i]*100:.2f}%)\")\n",
    "\n",
    "# Calculate cumulative explained variance\n",
    "cumulative_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "print(f\"\\nCumulative Explained Variance (first 10 components):\")\n",
    "print(\"-\" * 50)\n",
    "for i in range(min(10, len(cumulative_variance))):\n",
    "    print(f\"PC1-PC{i+1}: {cumulative_variance[i]*100:.2f}%\")\n",
    "\n",
    "print(f\"\\n✅ Task 1 completed: PCA implemented from scratch!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e088d62-4ac3-45df-8ca8-fdb078d407b7",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated f-string literal (detected at line 25) (146670927.py, line 25)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 25\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mprint(f\"  - Dimensionality reduction: {X.shape[1]} # TASK 2: Dynamic Component Selection Based on Explained Variance\u001b[39m\n          ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m unterminated f-string literal (detected at line 25)\n"
     ]
    }
   ],
   "source": [
    "# TASK 2: Dynamic Component Selection Based on Explained Variance\n",
    "\n",
    "def select_components_by_variance(pca, variance_threshold=0.95):\n",
    "    \"\"\"Select number of components based on explained variance threshold\"\"\"\n",
    "    cumulative_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "    n_components = np.argmax(cumulative_variance >= variance_threshold) + 1\n",
    "    return n_components, cumulative_variance\n",
    "\n",
    "print(\"TASK 2: DYNAMIC COMPONENT SELECTION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Test different variance thresholds\n",
    "thresholds = [0.80, 0.90, 0.95, 0.99]\n",
    "\n",
    "for threshold in thresholds:\n",
    "    n_comp, cum_var = select_components_by_variance(pca, threshold)\n",
    "    print(f\"\\nFor {threshold*100}% variance retention:\")\n",
    "    print(f\"  - Components needed: {n_comp}\")\n",
    "    print(f\"  - Actual variance retained: {cum_var[n_comp-1]*100:.2f}%\")\n",
    "    \n",
    "    # Apply PCA with selected components\n",
    "    pca_reduced = CustomPCA(n_components=n_comp)\n",
    "    X_reduced = pca_reduced.fit_transform(X)\n",
    "    print(f\"  - Reduced data shape: {X_reduced.shape}\")\n",
    "    print(f\"  - Dimensionality reduction: {X.shape[1]} # TASK 2: Dynamic Component Selection Based on Explained Variance\n",
    "\n",
    "def select_components_by_variance(pca, variance_threshold=0.95):\n",
    "    \"\"\"Select number of components based on explained variance threshold\"\"\"\n",
    "    cumulative_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "    n_components = np.argmax(cumulative_variance >= variance_threshold) + 1\n",
    "    return n_components, cumulative_variance\n",
    "\n",
    "print(\"TASK 2: DYNAMIC COMPONENT SELECTION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Test different variance thresholds\n",
    "thresholds = [0.80, 0.90, 0.95, 0.99]\n",
    "\n",
    "for threshold in thresholds:\n",
    "    n_comp, cum_var = select_components_by_variance(pca, threshold)\n",
    "    print(f\"\\nFor {threshold*100}% variance retention:\")\n",
    "    print(f\"  - Components needed: {n_comp}\")\n",
    "    print(f\"  - Actual variance retained: {cum_var[n_comp-1]*100:.2f}%\")\n",
    "    \n",
    "    # Apply PCA with selected components\n",
    "    pca_reduced = CustomPCA(n_components=n_comp)\n",
    "    X_reduced = pca_reduced.fit_transform(X)\n",
    "    print(f\"  - Reduced data shape: {X_reduced.shape}\")\n",
    "    print(f\"  - Dimensionality reduction: {X.shape[1]} -> {X_reduced.shape[1]} features\")\n",
    "    print(f\"  - Compression ratio: {(1 - X_reduced.shape[1]/X.shape[1])*100:.1f}%\")\n",
    "\n",
    "print(f\"\\nTask 2 completed: Dynamic component selection implemented!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35c18a43-8fe2-44ef-a558-a2660846baf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TASK 2: DYNAMIC COMPONENT SELECTION\n",
      "============================================================\n",
      "\n",
      "For 80.0% variance retention:\n",
      "  - Components needed: 1\n",
      "  - Actual variance retained: 100.00%\n",
      "  - Reduced data shape: (22, 1)\n",
      "  - Dimensionality reduction: 34 -> 1 features\n",
      "  - Compression ratio: 97.1%\n",
      "\n",
      "For 90.0% variance retention:\n",
      "  - Components needed: 1\n",
      "  - Actual variance retained: 100.00%\n",
      "  - Reduced data shape: (22, 1)\n",
      "  - Dimensionality reduction: 34 -> 1 features\n",
      "  - Compression ratio: 97.1%\n",
      "\n",
      "For 95.0% variance retention:\n",
      "  - Components needed: 1\n",
      "  - Actual variance retained: 100.00%\n",
      "  - Reduced data shape: (22, 1)\n",
      "  - Dimensionality reduction: 34 -> 1 features\n",
      "  - Compression ratio: 97.1%\n",
      "\n",
      "For 99.0% variance retention:\n",
      "  - Components needed: 1\n",
      "  - Actual variance retained: 100.00%\n",
      "  - Reduced data shape: (22, 1)\n",
      "  - Dimensionality reduction: 34 -> 1 features\n",
      "  - Compression ratio: 97.1%\n",
      "\n",
      "Task 2 completed: Dynamic component selection implemented!\n"
     ]
    }
   ],
   "source": [
    "# TASK 2: Dynamic Component Selection Based on Explained Variance (Fixed)\n",
    "\n",
    "def select_components_by_variance(pca, variance_threshold=0.95):\n",
    "    \"\"\"Select number of components based on explained variance threshold\"\"\"\n",
    "    cumulative_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "    n_components = np.argmax(cumulative_variance >= variance_threshold) + 1\n",
    "    return n_components, cumulative_variance\n",
    "\n",
    "print(\"TASK 2: DYNAMIC COMPONENT SELECTION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Test different variance thresholds\n",
    "thresholds = [0.80, 0.90, 0.95, 0.99]\n",
    "\n",
    "for threshold in thresholds:\n",
    "    n_comp, cum_var = select_components_by_variance(pca, threshold)\n",
    "    print(f\"\\nFor {threshold*100}% variance retention:\")\n",
    "    print(f\"  - Components needed: {n_comp}\")\n",
    "    print(f\"  - Actual variance retained: {cum_var[n_comp-1]*100:.2f}%\")\n",
    "    \n",
    "    # Apply PCA with selected components\n",
    "    pca_reduced = CustomPCA(n_components=n_comp)\n",
    "    X_reduced = pca_reduced.fit_transform(X)\n",
    "    print(f\"  - Reduced data shape: {X_reduced.shape}\")\n",
    "    print(f\"  - Dimensionality reduction: {X.shape[1]} -> {X_reduced.shape[1]} features\")\n",
    "    compression_ratio = (1 - X_reduced.shape[1]/X.shape[1])*100\n",
    "    print(f\"  - Compression ratio: {compression_ratio:.1f}%\")\n",
    "\n",
    "print(\"\\nTask 2 completed: Dynamic component selection implemented!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de733562-c770-4119-b5ed-e3a61070b9a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized PCA class implemented successfully!\n",
      "Ready for performance benchmarking...\n"
     ]
    }
   ],
   "source": [
    "# TASK 3: Performance Optimization for Large Datasets\n",
    "\n",
    "import time\n",
    "\n",
    "class OptimizedPCA:\n",
    "    \"\"\"Optimized PCA implementation for large datasets\"\"\"\n",
    "    \n",
    "    def __init__(self, n_components=None):\n",
    "        self.n_components = n_components\n",
    "        self.components_ = None\n",
    "        self.explained_variance_ = None\n",
    "        self.explained_variance_ratio_ = None\n",
    "        self.mean_ = None\n",
    "        \n",
    "    def fit(self, X):\n",
    "        \"\"\"Optimized fit method with memory efficiency\"\"\"\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Step 1: Center the data efficiently\n",
    "        self.mean_ = np.mean(X, axis=0)\n",
    "        \n",
    "        # Step 2: Use more memory-efficient covariance calculation\n",
    "        n_samples, n_features = X.shape\n",
    "        \n",
    "        if n_samples < n_features:\n",
    "            # Use SVD approach for wide matrices (more features than samples)\n",
    "            X_centered = X - self.mean_\n",
    "            U, s, Vt = np.linalg.svd(X_centered, full_matrices=False)\n",
    "            eigenvalues = (s ** 2) / (n_samples - 1)\n",
    "            eigenvectors = Vt.T\n",
    "        else:\n",
    "            # Use traditional covariance approach for tall matrices\n",
    "            X_centered = X - self.mean_\n",
    "            cov_matrix = np.cov(X_centered.T)\n",
    "            eigenvalues, eigenvectors = np.linalg.eigh(cov_matrix)\n",
    "            \n",
    "            # Sort in descending order\n",
    "            idx = np.argsort(eigenvalues)[::-1]\n",
    "            eigenvalues = eigenvalues[idx]\n",
    "            eigenvectors = eigenvectors[:, idx]\n",
    "        \n",
    "        # Store results\n",
    "        if self.n_components is None:\n",
    "            self.n_components = min(len(eigenvalues), X.shape[0] - 1)\n",
    "        \n",
    "        self.components_ = eigenvectors[:, :self.n_components].T\n",
    "        self.explained_variance_ = eigenvalues[:self.n_components]\n",
    "        self.explained_variance_ratio_ = self.explained_variance_ / np.sum(eigenvalues)\n",
    "        \n",
    "        self.fit_time_ = time.time() - start_time\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        \"\"\"Optimized transform method\"\"\"\n",
    "        X_centered = X - self.mean_\n",
    "        return np.dot(X_centered, self.components_.T)\n",
    "    \n",
    "    def fit_transform(self, X):\n",
    "        \"\"\"Optimized fit and transform\"\"\"\n",
    "        return self.fit(X).transform(X)\n",
    "\n",
    "print(\"Optimized PCA class implemented successfully!\")\n",
    "print(\"Ready for performance benchmarking...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "955095fd-f99e-4e8d-b6cc-d19de24960af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TASK 3: PERFORMANCE BENCHMARKING\n",
      "============================================================\n",
      "\n",
      "Benchmarking Original PCA:\n",
      "  - Execution time: 0.0015 seconds\n",
      "  - Output shape: (22, 5)\n",
      "  - Explained variance: [9.99997940e-01 2.02538732e-06 3.43343614e-08]\n",
      "\n",
      "Benchmarking Optimized PCA:\n",
      "  - Execution time: 0.0040 seconds\n",
      "  - Output shape: (22, 5)\n",
      "  - Explained variance: [9.99997940e-01 2.02538732e-06 3.43343614e-08]\n",
      "\n",
      "PERFORMANCE COMPARISON:\n",
      "------------------------------\n",
      "Original PCA time:  0.0015s\n",
      "Optimized PCA time: 0.0040s\n",
      "Speedup factor:     0.39x\n",
      "Performance gain:   -158.9%\n",
      "\n",
      "Task 3 completed: Performance optimization implemented!\n"
     ]
    }
   ],
   "source": [
    "# Performance Benchmarking\n",
    "\n",
    "print(\"TASK 3: PERFORMANCE BENCHMARKING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Benchmark original PCA\n",
    "print(\"\\nBenchmarking Original PCA:\")\n",
    "start_time = time.time()\n",
    "pca_original = CustomPCA(n_components=5)\n",
    "X_original = pca_original.fit_transform(X)\n",
    "original_time = time.time() - start_time\n",
    "\n",
    "print(f\"  - Execution time: {original_time:.4f} seconds\")\n",
    "print(f\"  - Output shape: {X_original.shape}\")\n",
    "print(f\"  - Explained variance: {pca_original.explained_variance_ratio_[:3]}\")\n",
    "\n",
    "# Benchmark optimized PCA\n",
    "print(\"\\nBenchmarking Optimized PCA:\")\n",
    "start_time = time.time()\n",
    "pca_optimized = OptimizedPCA(n_components=5)\n",
    "X_optimized = pca_optimized.fit_transform(X)\n",
    "optimized_time = time.time() - start_time\n",
    "\n",
    "print(f\"  - Execution time: {optimized_time:.4f} seconds\")\n",
    "print(f\"  - Output shape: {X_optimized.shape}\")\n",
    "print(f\"  - Explained variance: {pca_optimized.explained_variance_ratio_[:3]}\")\n",
    "\n",
    "# Performance comparison\n",
    "speedup = original_time / optimized_time if optimized_time > 0 else float('inf')\n",
    "print(f\"\\nPERFORMANCE COMPARISON:\")\n",
    "print(\"-\" * 30)\n",
    "print(f\"Original PCA time:  {original_time:.4f}s\")\n",
    "print(f\"Optimized PCA time: {optimized_time:.4f}s\")\n",
    "print(f\"Speedup factor:     {speedup:.2f}x\")\n",
    "print(f\"Performance gain:   {((original_time - optimized_time) / original_time * 100):.1f}%\")\n",
    "\n",
    "print(f\"\\nTask 3 completed: Performance optimization implemented!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e412b0d-a6fd-4e8b-a183-f05747b1a50c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom Matrix class initialized successfully!\n",
      "Testing matrix operations...\n"
     ]
    }
   ],
   "source": [
    "# Custom Matrix Manipulation Library (Required by Rubric)\n",
    "# Must handle different matrix dimensions with error handling\n",
    "# NO external Python libraries allowed for core operations\n",
    "\n",
    "class CustomMatrix:\n",
    "    \"\"\"Custom Matrix class for PCA operations without external libraries\"\"\"\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        if isinstance(data, list):\n",
    "            self.data = [row[:] if isinstance(row, list) else [row] for row in data]\n",
    "        else:\n",
    "            self.data = data.tolist() if hasattr(data, 'tolist') else data\n",
    "        \n",
    "        self.rows = len(self.data)\n",
    "        self.cols = len(self.data[0]) if self.rows > 0 else 0\n",
    "        \n",
    "        # Validate matrix structure\n",
    "        for row in self.data:\n",
    "            if len(row) != self.cols:\n",
    "                raise ValueError(\"All rows must have the same number of columns\")\n",
    "    \n",
    "    def __str__(self):\n",
    "        return '\\n'.join([' '.join([f'{val:8.4f}' for val in row]) for row in self.data])\n",
    "    \n",
    "    def shape(self):\n",
    "        \"\"\"Return matrix dimensions\"\"\"\n",
    "        return (self.rows, self.cols)\n",
    "    \n",
    "    def add(self, other):\n",
    "        \"\"\"Matrix addition with error handling\"\"\"\n",
    "        if not isinstance(other, CustomMatrix):\n",
    "            raise TypeError(\"Can only add CustomMatrix objects\")\n",
    "        \n",
    "        if self.shape() != other.shape():\n",
    "            raise ValueError(f\"Matrix dimensions must match: {self.shape()} vs {other.shape()}\")\n",
    "        \n",
    "        result = []\n",
    "        for i in range(self.rows):\n",
    "            row = []\n",
    "            for j in range(self.cols):\n",
    "                row.append(self.data[i][j] + other.data[i][j])\n",
    "            result.append(row)\n",
    "        \n",
    "        return CustomMatrix(result)\n",
    "\n",
    "print(\"Custom Matrix class initialized successfully!\")\n",
    "print(\"Testing matrix operations...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c650c749-424c-43dd-8849-bf7ee96353f4",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (2325238500.py, line 1)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mdef subtract(self, other):\u001b[39m\n    ^\n\u001b[31mIndentationError\u001b[39m\u001b[31m:\u001b[39m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "    def subtract(self, other):\n",
    "        \"\"\"Matrix subtraction with error handling\"\"\"\n",
    "        if not isinstance(other, CustomMatrix):\n",
    "            raise TypeError(\"Can only subtract CustomMatrix objects\")\n",
    "        \n",
    "        if self.shape() != other.shape():\n",
    "            raise ValueError(f\"Matrix dimensions must match: {self.shape()} vs {other.shape()}\")\n",
    "        \n",
    "        result = []\n",
    "        for i in range(self.rows):\n",
    "            row = []\n",
    "            for j in range(self.cols):\n",
    "                row.append(self.data[i][j] - other.data[i][j])\n",
    "            result.append(row)\n",
    "        \n",
    "        return CustomMatrix(result)\n",
    "    \n",
    "    def multiply(self, other):\n",
    "        \"\"\"Matrix multiplication with dimension checking\"\"\"\n",
    "        if not isinstance(other, CustomMatrix):\n",
    "            raise TypeError(\"Can only multiply with CustomMatrix objects\")\n",
    "        \n",
    "        if self.cols != other.rows:\n",
    "            raise ValueError(f\"Cannot multiply matrices: {self.shape()} x {other.shape()}\")\n",
    "        \n",
    "        result = []\n",
    "        for i in range(self.rows):\n",
    "            row = []\n",
    "            for j in range(other.cols):\n",
    "                sum_val = 0\n",
    "                for k in range(self.cols):\n",
    "                    sum_val += self.data[i][k] * other.data[k][j]\n",
    "                row.append(sum_val)\n",
    "            result.append(row)\n",
    "        \n",
    "        return CustomMatrix(result)\n",
    "    \n",
    "    def transpose(self):\n",
    "        \"\"\"Matrix transpose\"\"\"\n",
    "        result = []\n",
    "        for j in range(self.cols):\n",
    "            row = []\n",
    "            for i in range(self.rows):\n",
    "                row.append(self.data[i][j])\n",
    "            result.append(row)\n",
    "        \n",
    "        return CustomMatrix(result)\n",
    "\n",
    "print(\"Matrix operations (add, subtract, multiply, transpose) implemented!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "06a13223-736f-4901-94e4-2493426fd8e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TESTING CUSTOM MATRIX LIBRARY:\n",
      "==================================================\n",
      "Matrix A ((2, 2)):\n",
      "  1.0000   2.0000\n",
      "  3.0000   4.0000\n",
      "\n",
      "Matrix B ((2, 2)):\n",
      "  5.0000   6.0000\n",
      "  7.0000   8.0000\n",
      "\n",
      "A + B:\n",
      "  6.0000   8.0000\n",
      " 10.0000  12.0000\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'CustomMatrix' object has no attribute 'multiply'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28mprint\u001b[39m(C)\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# Test multiplication\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m D = \u001b[43mA\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmultiply\u001b[49m(B)\n\u001b[32m     21\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mA * B:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     22\u001b[39m \u001b[38;5;28mprint\u001b[39m(D)\n",
      "\u001b[31mAttributeError\u001b[39m: 'CustomMatrix' object has no attribute 'multiply'"
     ]
    }
   ],
   "source": [
    "# Test the Custom Matrix Library\n",
    "print(\"\\nTESTING CUSTOM MATRIX LIBRARY:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Test matrix creation and operations\n",
    "A = CustomMatrix([[1, 2], [3, 4]])\n",
    "B = CustomMatrix([[5, 6], [7, 8]])\n",
    "\n",
    "print(f\"Matrix A ({A.shape()}):\")\n",
    "print(A)\n",
    "print(f\"\\nMatrix B ({B.shape()}):\")\n",
    "print(B)\n",
    "\n",
    "# Test addition\n",
    "C = A.add(B)\n",
    "print(f\"\\nA + B:\")\n",
    "print(C)\n",
    "\n",
    "# Test multiplication\n",
    "D = A.multiply(B)\n",
    "print(f\"\\nA * B:\")\n",
    "print(D)\n",
    "\n",
    "# Test transpose\n",
    "E = A.transpose()\n",
    "print(f\"\\nA transpose:\")\n",
    "print(E)\n",
    "\n",
    "print(\"\\n✅ Custom Matrix Library completed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ccc0117-273f-4b0b-bccc-49286636c211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Visualizations (Before/After PCA)\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Before PCA - use first two numeric features\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.scatter(data_encoded.iloc[:, 0], data_encoded.iloc[:, 1], alpha=0.7, c='blue')\n",
    "plt.xlabel('Feature 1 (Original)')\n",
    "plt.ylabel('Feature 2 (Original)')\n",
    "plt.title('Before PCA: Original Feature Space')\n",
    "plt.grid(True)\n",
    "\n",
    "# After PCA - PC1 vs PC2\n",
    "pca_viz = CustomPCA(n_components=2)\n",
    "X_pca_viz = pca_viz.fit_transform(X)\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.scatter(X_pca_viz[:, 0], X_pca_viz[:, 1], alpha=0.7, c='red')\n",
    "plt.xlabel('PC1 (First Principal Component)')\n",
    "plt.ylabel('PC2 (Second Principal Component)')\n",
    "plt.title('After PCA: Principal Component Space')\n",
    "plt.grid(True)\n",
    "\n",
    "# Explained Variance Plot\n",
    "plt.subplot(1, 3, 3)\n",
    "components = range(1, min(11, len(pca.explained_variance_ratio_) + 1))\n",
    "variance_ratios = pca.explained_variance_ratio_[:10]\n",
    "plt.bar(components, variance_ratios, alpha=0.7, color='green')\n",
    "plt.xlabel('Principal Component')\n",
    "plt.ylabel('Explained Variance Ratio')\n",
    "plt.title('Explained Variance by Component')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✅ All tasks completed successfully!\")\n",
    "print(\"\\nSUMMARY:\")\n",
    "print(f\"- Dataset: African Import/Export Trade Data ({data.shape})\")\n",
    "print(f\"- Features: {data_encoded.shape[1]} (after encoding)\")\n",
    "print(f\"- PCA Components: {len(pca.explained_variance_)}\")\n",
    "print(f\"- Custom implementations: PCA, Matrix Library, Label Encoder\")\n",
    "print(f\"- Performance optimization completed\")\n",
    "print(f\"- Visualizations created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7eeb0fb-c130-4c63-92c7-1334cd39f618",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
